{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Klooker.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M4_9AumteUF",
        "colab_type": "code",
        "outputId": "d689b074-7721-413e-e512-82c718b07e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import sklearn \n",
        "import nltk\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3xfp0u9lrCm",
        "colab_type": "code",
        "outputId": "bcd20327-1e95-4b56-fc03-19e72a433288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmna3en9mpQo",
        "colab_type": "code",
        "outputId": "b7ed3e7e-5ec9-4106-b027-2ab24dbe46c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format('/gdrive/My Drive/Pretrained_models/cc.en.300.vec')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdx01XpO12G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = {}\n",
        "for key,val in model.vocab.items():\n",
        "  embeddings[key] = model[key]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-BCzL_kUXN2",
        "colab_type": "code",
        "outputId": "a5019b2d-2bb9-40a3-bf02-1ab4422e7692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embeddings))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOQ7pxjN5kfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYn7RrmHVMIV",
        "colab_type": "code",
        "outputId": "139c610d-7404-44e7-bd79-f41ec96b49af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILXMFZCcZW_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/gdrive/My Drive/amazon_only_english_normalised_book_reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFbDa-PykYH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_lines = []\n",
        "lines = df['normalised'].values.tolist()\n",
        "for line in lines:\n",
        "  tokens = word_tokenize(line)\n",
        "  words = [word for word in tokens if word.isalpha()]\n",
        "  main_lines.append(words)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdC-leJsZyxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(main_lines)\n",
        "sequences = tokenizer_obj.texts_to_sequences(main_lines)\n",
        "word_index = tokenizer_obj.word_index\n",
        "description = pad_sequences(sequences,maxlen = 150)\n",
        "rating = df['rating'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD3ETVohxta1",
        "colab_type": "code",
        "outputId": "68460674-2c3c-4ae2-c161-ab11219be220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('shape of description tensor',description.shape)\n",
        "print('shape of categories',rating.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of description tensor (2993106, 150)\n",
            "shape of categories (2993106,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMbcn3YJz2_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMXLi159ijkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words,EMBEDDING_DIM))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKZ-bBSq7ISq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/gdrive/My Drive/word_index.pkl','wb') as f1:\n",
        "  pickle.dump(word_index,f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va1wwyXg09EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word,i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjYH9_lP2t1G",
        "colab_type": "code",
        "outputId": "a71f4962-e487-4c14-8043-eaff3da4ee35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "nlp_model = Sequential()\n",
        "embedding_layer = Embedding(num_words,EMBEDDING_DIM,embeddings_initializer = Constant(embedding_matrix),input_length = 150,trainable = False)\n",
        "nlp_model.add(embedding_layer)\n",
        "nlp_model.add(GRU(units=96,dropout=0.2,recurrent_dropout=0.2))\n",
        "nlp_model.add(Dense(71,activation = 'softmax'))\n",
        "nlp_model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "nlp_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 03:58:24.699965 139842046162816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0905 03:58:24.765012 139842046162816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0905 03:58:25.061614 139842046162816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0905 03:58:25.180266 139842046162816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0905 03:58:25.195819 139842046162816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0905 03:58:25.431661 139842046162816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0905 03:58:25.453381 139842046162816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 300)          13731300  \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 96)                114336    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 71)                6887      \n",
            "=================================================================\n",
            "Total params: 13,852,523\n",
            "Trainable params: 121,223\n",
            "Non-trainable params: 13,731,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dHfUslUhXZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_file = 'klooker_nlp_best_new'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBrhD3Y7gDL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='/gdrive/My Drive/' + output_file + \".hdf5\", verbose=1, save_best_only=True)\n",
        "earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA6eu80j9NNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(description, categories, test_size=0.5, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hztQURv_TO4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_id = {i:index for index,i in enumerate(set(categories))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D3PA_aIUJLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "\n",
        "tmp = np.zeros(71,dtype=np.int16)\n",
        "y_train_sm = []\n",
        "y_test_sm = []\n",
        "\n",
        "for i in y_train:\n",
        "  val = labels_id[i]\n",
        "  new = copy.deepcopy(tmp)\n",
        "  new[val] = 1\n",
        "  y_train_sm.append(new)\n",
        "for k in y_test:\n",
        "  val1 = labels_id[k]\n",
        "  new1 = copy.deepcopy(tmp)\n",
        "  new1[val1] = 1\n",
        "  y_test_sm.append(new1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0kW3W6VG6UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_sm_arr = np.asarray(y_train_sm)\n",
        "y_test_sm_arr = np.asarray(y_test_sm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlDoudx193QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_model.fit(x_train,y_train_sm_arr,batch_size=80,epochs = 150,validation_data=(x_test,y_test_sm_arr),verbose=2,callbacks=[checkpointer, earlystopper])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}